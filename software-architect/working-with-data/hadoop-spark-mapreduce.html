<div data-github-url="https://github.com/kamranahmedse/developer-roadmap/tree/master/src/data/roadmaps/software-architect/content/109-working-with-data/100-hadoop-spark-mapreduce.md"></div> <h1 id="spark-hadoop-mapreduce">Spark, Hadoop MapReduce</h1>
<p><a href="https://spark.apache.org/" rel="noopener noreferrer nofollow" target="_blank">Apache Spark</a> is a data processing framework that can quickly perform processing tasks on very large data sets, and can also distribute data processing tasks across multiple computers, either on its own or in tandem with other distributed computing tools.</p>
<p>Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner.</p>
<p>Visit the following resources to learn more:</p>
<ul>
<li><a href="https://www.integrate.io/blog/apache-spark-vs-hadoop-mapreduce" rel="noopener noreferrer nofollow" target="_blank">Spark vs Hadoop MapReduce</a></li>
<li><a href="https://www.youtube.com/watch?v=aReuLtY0YMI" rel="noopener noreferrer nofollow" target="_blank">Hadoop explained in 5 minutes</a></li>
</ul>