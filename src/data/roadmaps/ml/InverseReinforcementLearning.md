# Inverse Reinforcement Learning

Inverse Reinforcement Learning (IRL) is a subfield of machine learning that aims to infer the underlying reward function of an agent's behavior from a set of observed trajectories, without any prior knowledge of the reward function. In other words, IRL tries to learn the goals or objectives of an agent based on the observed behavior.

In Reinforcement Learning (RL), an agent interacts with an environment and receives rewards based on its actions. The goal of the agent is to learn a policy that maximizes its expected cumulative reward. However, in some cases, the reward function is not known in advance, and the agent must learn it from experience. This is where IRL comes in.

IRL works by assuming that the observed behavior of the agent is optimal with respect to some unknown reward function. It then tries to infer this reward function by solving an optimization problem that balances the fit of the observed behavior with the simplicity of the reward function. The resulting reward function is usually expressed as a linear combination of features that capture relevant aspects of the agent's behavior, such as distance traveled, time spent, or resources used.

</br>

# Sources of Inverse Reinforcement Learning

- [IRL by Analyticssteps](https://www.analyticssteps.com/blogs/what-inverse-reinforcement-learning)
  
- [IRL by thegrafient](https://thegradient.pub/learning-from-humans-what-is-inverse-reinforcement-learning/)

- [IRL by Pascal](https://www.youtube.com/watch?v=kkC1xpdUSTQ)

- [IRL Examples](https://www.youtube.com/watch?v=h7uGyBcIeII)

- [IRL by AI Prism](https://www.youtube.com/watch?v=d9DlQSJQAoI)