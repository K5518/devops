# Underfitting

A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data, i.e., it only performs well on training data but performs poorly on testing data. (Itâ€™s just like trying to fit undersized pants!) Underfitting destroys the accuracy of our machine learning model. Its occurrence simply means that our model or the algorithm does not fit the data well enough. It usually happens when we have fewer data to build an accurate model and also when we try to build a linear model with fewer non-linear data. In such cases, the rules of the machine learning model are too easy and flexible to be applied to such minimal data and therefore the model will probably make a lot of wrong predictions. Underfitting can be avoided by using more data and also reducing the features by feature selection.

- [Overfitting](https://youtu.be/nj_hChhSrOI)   
- [Underfitting](https://youtu.be/jnAeZ8j0Ur0)   
- [Expanation of Overfitting and Underfitting](https://youtu.be/T9NtOa-IITo)   
- [Overcoming of Overfitting and Underfitting](https://youtu.be/nj_hChhSrOI)
- [Data Science Fundamentals for Data Analysts](https://www.coursera.org/lecture/data-science-fundamentals-for-data-analysts/overfitting-and-underfitting-vhRrM)

