# GradientBoost resources

Gradient Boosting is a machine learning technique that produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. Gradient Boosting iteratively trains the ensemble of models by fitting the next model to the residual errors of the previous models, and then combining the predictions of all models to produce a final prediction. Gradient Boosting is known for its ability to produce accurate predictions even with complex and high-dimensional data.

- [Introduction to Gradient Boosting:](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)A tutorial on Gradient Boosting with XGBoost, a popular implementation of Gradient Boosting. 
- [Gradient Boosting from Scratch:](https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d) A tutorial on Gradient Boosting from scratch, without using any existing implementation. 
- [Gradient Boosting in Python with Scikit-Learn:](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) A tutorial on Gradient Boosting with scikit-learn, a popular machine learning library in Python.
- [The Elements of Statistical Learning:](https://hastie.su.domains/Papers/ESLII.pdf)  A classic textbook on statistical learning, which covers Gradient Boosting and many other machine learning techniques.
- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow:](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
- [ XGBoost:](https://github.com/dmlc/xgboost) 
- [LightGBM:](https://github.com/microsoft/LightGBM)  
- [CatBoost:](https://github.com/catboost/catboost)