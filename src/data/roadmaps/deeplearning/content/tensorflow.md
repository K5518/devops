# Tensorflow Lite 

TensorFlow Lite is a lightweight version of the popular deep learning framework TensorFlow that is specifically designed to run on mobile and embedded devices with limited computational resources. It allows developers to deploy machine learning models to these devices, enabling them to run inference locally, without needing to rely on cloud-based servers.TensorFlow Lite includes a variety of resources and tools, including the TensorFlow Lite Converter, which allows you to convert TensorFlow models into the TensorFlow Lite format, and the TensorFlow Lite Interpreter, which is a runtime that allows you to run TensorFlow Lite models on mobile and embedded devices. There is also TensorFlow Lite for Microcontrollers, which is a highly optimized version of TensorFlow Lite designed to run on microcontrollers with very limited memory and processing powertensorFlow Lite also provides a variety of example models and code samples, as well as the TensorFlow Lite Model Maker, which is a high-level API that allows you to create custom TensorFlow Lite models without writing any code. Overall, TensorFlow Lite is a powerful and flexible platform for deploying machine learning models to mobile and embedded devices.

- [what is Tensorflow lite resource ?](https://en.wikipedia.org/wiki/TensorFlow#:~:text=TensorFlow%20is%20a%20free%20and,inference%20of%20deep%20neural%20networks.)
- [how does work Tensorflow lite resource ?](https://viso.ai/edge-ai/tensorflow-lite/)
- [Introduction to Tensorflow lite resources ](https://www.tensorflow.org/lite/guide)
- [Tensorflow lite resources.coursera](https://in.coursera.org/learn/device-based-models-tensorflow)
