# Gradient Descent 

Introduction

Gradient Descent is an optimization algorithm commonly used in machine learning and deep learning to minimize the cost function of a model. The cost function measures how well the model is performing in terms of its ability to make accurate predictions. In Gradient Descent, the goal is to find the set of parameters that minimizes the cost function. The algorithm achieves this by iteratively updating the parameters in the direction of steepest descent of the cost function, which is the negative gradient. In other words, it adjusts the parameters in small steps that reduce the error between the predicted and actual values

Visit the following resources to learn more:

-  [What is Gradient Descent ? ](https://builtin.com/data-science/gradient-descent)

- [How Does Gradient descent work and its type](https://www.ibm.com/in-en/topics/gradient-descent)
- [Gradient descent simple explanation](https://youtu.be/gzrQvzYEvYc)
-  [Gradient descent Great learning](https://www.mygreatlearning.com/academy/learn-for-free/courses/stochastic-gradient-descent?utm_source=share_with_friends&gl_source=share_with_friends)
